{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm_Detection_in_News_Headlines.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSZwG4Ov+OGs76uXBioyB0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjali-Shalimar/Detecting-Sarcasm-in-News-Headlines/blob/master/Sarcasm_Detection_in_News_Headlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6LWpsTNWw-y",
        "colab_type": "text"
      },
      "source": [
        "# **Sarcasm Detection in News Headlines**\n",
        "\n",
        "The purpose of this project is to build a tool to be able to detect sarcasm in sentences.\n",
        "\n",
        "**Data**: The data we are working with is headlines from various news articles marked as either sarcastic or not sarcastic. The columns in the dataset are:\n",
        "\n",
        "1. The headline\n",
        "2. The article's link (we'll disregard this column)\n",
        "3. Label of whether the headline is sarcastic or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyTNf_C4XOsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "9bcafdc4-cd7e-4128-fa42-ccca3858f6c0"
      },
      "source": [
        "#@title Package imports\n",
        "#Import\n",
        "!pip install keras\n",
        "!pip install tensorflow\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Embedding, LSTM, GlobalAveragePooling1D, Flatten\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "import random\n",
        "\n",
        "random.seed(9176932)\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ckRPR9Xv26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1182d547-b64e-4560-ae6c-ca1c7bbc00b0"
      },
      "source": [
        "#@title Google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhyyuZS-XZ2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data read-in\n",
        "#reading in the file\n",
        "sarcasm_master = pd.read_json(\"/content/gdrive/My Drive/Data Mining/sarcasm_master.json\",lines=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQEmUaRYzwM",
        "colab_type": "text"
      },
      "source": [
        "## **Data Preprocessing**\n",
        "\n",
        "Before we can feed the data to our model, we need to perform a few data preprocessing operations.\n",
        "\n",
        "**1. Removing punctuations:**\n",
        "\n",
        "Most text contains punctuations. In detecting sarcasm, the presence of punctuations doesn't necesarily contribute to the model performing better. So we aim to strip the data of all punctuations.\n",
        "\n",
        "**2. Remove digits:**\n",
        "\n",
        "We are going to vectorize our data and convert the strings to numbers. Presence of numbers in the data would not help in identifying the tone any better. Moreover the pre-existing digits might interfere with the vectorization process. Hence all numbers are removed as well.\n",
        "\n",
        "**3. Converting to lower case:**\n",
        "\n",
        "Converting the text to lower case helps make the data uniform.\n",
        "\n",
        "**4. Removing stop words:**\n",
        "\n",
        "Most headlines or any natural language data would contain stop words that are usually removed as stop words generally appear in abundance and do not provide any valuable information during classification.\n",
        "\n",
        "**5. Lemmatization:**\n",
        "\n",
        "Lemmatization is the process by which any inflected version of a word is converted to its base word so that all forms of a word are treated the same.\n",
        "\n",
        "**6. Vectorization and padding:**\n",
        "\n",
        "Vectorization is the process by which words are mapped to the numeric vectors. For LSTM model, the input should be of same size. Hence we pad the vectors with zeros to ensure uniformity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apcS9zDQZjNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Preliminary text processing\n",
        "#Removing punctuation and digits and converting to lower case\n",
        "#Punctuation\n",
        "sarcasm_master['punct_headline'] = sarcasm_master['headline'].apply(lambda x : re.sub(r'[^a-zA-Z\\s]','', x ) )\n",
        "\n",
        "#Removing digits\n",
        "sarcasm_master['digits_headline'] = sarcasm_master['punct_headline'].apply(lambda x :re.sub(\"\\d+\", \"\", x)) \n",
        "\n",
        "#Converting to lower case\n",
        "sarcasm_master['lc_headline'] = sarcasm_master['digits_headline'].apply(lambda x : x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVNvkLX0ZL8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Remove stop words\n",
        "def rem_stp(input_series):\n",
        "    words = word_tokenize(input_series)\n",
        "    a = [w for w in words] \n",
        "    return(a)\n",
        "\n",
        "sarcasm_master['rem_stp_headline'] = sarcasm_master['lc_headline'].apply(rem_stp) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYOTJrwvaIQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    #@title Lemmatization\n",
        "    #Lemmatization\n",
        "    lmt = WordNetLemmatizer()\n",
        "    def lem_fn(input_series):\n",
        "        a  =  [lmt.lemmatize(word) for word in input_series ]\n",
        "        return(a)\n",
        "\n",
        "    sarcasm_master['lem_headline'] = sarcasm_master['rem_stp_headline'].apply(lem_fn) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSvZ3SVoaPOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Vectorization\n",
        "#Vectorization \n",
        "\n",
        "tkn = Tokenizer(num_words=10000)\n",
        "tkn.fit_on_texts(sarcasm_master['lem_headline'])\n",
        "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['lem_headline'])\n",
        "\n",
        "total_words = len(tkn.word_index)\n",
        "\n",
        "#Add padding in front for the tokenized list\n",
        "\n",
        "#Find max length of the headline array length to add as maximum pad length\n",
        "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVN5T4GeaWkJ",
        "colab_type": "text"
      },
      "source": [
        "##**Building Keras Model** \n",
        "We are going to be building a Keras Model.\n",
        "\n",
        "**1. Embedding layer**\n",
        "\n",
        "The Embedding layer is used to create word vectors for incoming words. It sits between the input and the LSTM layer, i.e. the output of the Embedding layer is the input to the LSTM layer.\n",
        "\n",
        "**2. LSTM Layer**\n",
        "\n",
        "The LSTM transforms the vector sequence into a single vector containing information about the entire sequence.\n",
        "\n",
        "**3. Intermediate Layer**\n",
        "\n",
        "There is a Dense intermediate layer with 64 neurons and with activation function relu.\n",
        "\n",
        "**4. Output Layer**\n",
        "\n",
        "The final ouput we want from this model is whether the headline is sarcastic or not. So we want to perform classification. The output layer's activation function is thus sigmoid\n",
        "\n",
        "*Reference:*\n",
        "\n",
        "*Keras : https://keras.io/getting-started/sequential-model-guide/*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmYoaFxoawPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title build_model\n",
        "def build_model(X_train, y_train, X_test, y_test):\n",
        "  \n",
        "  embed_size = 128\n",
        "  model = Sequential()\n",
        "  \n",
        "  #Embedding Layer\n",
        "  model.add(Embedding( total_words,embed_size))\n",
        "\n",
        "  #LSTM input layer\n",
        "  model.add(LSTM(embed_size, activation='relu'))\n",
        "  \n",
        "  #Intermediate layer\n",
        "  model.add(Dense(64, activation ='relu'))\n",
        "  \n",
        "  #OutputLayer\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  model.fit(X_train,y_train,epochs=2)\n",
        "\n",
        "  accuracy = model.evaluate(X_test, y_test)[1]\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa2-C9Cpa8-7",
        "colab_type": "text"
      },
      "source": [
        "## **Model 1 - Base model**\n",
        "We first build a base model with the following preprocessing.\n",
        "\n",
        "1. Remove punctuations, digits and convert the text to lowercase.\n",
        "2. Remove all the stopwords\n",
        "3. Perform Lemmatization\n",
        "4. Perform tokenization and pad the resulting sequence - Prepadding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZOesqbbFX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "96543667-77c5-48ed-9e6d-99a79120f7b1"
      },
      "source": [
        "#@title Base Model\n",
        "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
        "sarcasm_master['padded_headline'] = X.tolist()\n",
        "\n",
        "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "base_accuracy = build_model(X_train, y_train, X_test ,y_test )\n",
        "print(base_accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         3094656   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,234,561\n",
            "Trainable params: 3,234,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "21367/21367 [==============================] - 60s 3ms/step - loss: 0.4240 - accuracy: 0.7931\n",
            "Epoch 2/2\n",
            "21367/21367 [==============================] - 60s 3ms/step - loss: 0.2261 - accuracy: 0.9097\n",
            "5342/5342 [==============================] - 2s 425us/step\n",
            "0.8571696281433105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKLgb8Atc_aY",
        "colab_type": "text"
      },
      "source": [
        "**Results:**\n",
        "\n",
        "We see that we get an accuracy of about 84.7%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLZs1wHwdP8A",
        "colab_type": "text"
      },
      "source": [
        "## **Model 2 - Post padding**\n",
        "\n",
        "We first build a model very similar to the base model with the following change: After performing the tokenization, do post-padding\n",
        "\n",
        "**Example:** Before padding : [234,5,67,12]\n",
        "\n",
        "The max_length is 7\n",
        "\n",
        "Pre-padding: [0,0,0,0,234,5,67,12]\n",
        "\n",
        "Post-padding: [234,5,67,12,0,0,0,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH2SS5ipdZkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "5cd27a65-e406-44df-9530-93cbdd700830"
      },
      "source": [
        "#@title Post padding model\n",
        "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='post')\n",
        "sarcasm_master['post_padded_headline'] = X.tolist()\n",
        "\n",
        "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "post_padding_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
        "print(post_padding_accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         3094656   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,234,561\n",
            "Trainable params: 3,234,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "21367/21367 [==============================] - 60s 3ms/step - loss: 0.6851 - accuracy: 0.5861\n",
            "Epoch 2/2\n",
            "21367/21367 [==============================] - 58s 3ms/step - loss: 1.4679 - accuracy: 0.7714\n",
            "5342/5342 [==============================] - 2s 436us/step\n",
            "0.8041931986808777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0w26DmRnR7u",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "Surprisingly we see a huge drop in the accuracy now.\n",
        "\n",
        "The reason why this is because we are building a Long Short term memory model. When the padding is in the beginning, the useful content is at the back and is therefore the latest information the model takes in. This stays in memory and results in a better model.\n",
        "\n",
        "**We are going to proceed further with pre-padded sequence for future models.**\n",
        "\n",
        "*Reference: https://arxiv.org/pdf/1903.07288.pdf*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlunwHCanaYk",
        "colab_type": "text"
      },
      "source": [
        "## **Model 3 - Sans Lemmatization**\n",
        "\n",
        "We now build a model that is a modification of our base model. We want to see the effect of lemmatization. Lemmatization is the process by which any inflected version of a word is converted to its base word so that all forms of a word are treated the same.\n",
        "\n",
        "We want to see if in detecting sarcasm, the **effect of inflect** plays a role in improving the efficiency of our model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5W7-hBnnu-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "91be3956-f27c-47ef-9f57-c51defad2cb4"
      },
      "source": [
        "#@title Sans Lemmatization\n",
        "tkn = Tokenizer(num_words=10000)\n",
        "tkn.fit_on_texts(sarcasm_master['rem_stp_headline'])\n",
        "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['rem_stp_headline'])\n",
        "\n",
        "total_words = len(tkn.word_index)\n",
        "\n",
        "#Add padding in front for the tokenized list\n",
        "\n",
        "#Find max length of the headline array length to add as maximum pad length\n",
        "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
        "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
        "sarcasm_master['sanslem_headline'] = X.tolist()\n",
        "\n",
        "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "sans_lemmatization_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
        "print(sans_lemmatization_accuracy)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 128)         3534848   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,674,753\n",
            "Trainable params: 3,674,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "21367/21367 [==============================] - 64s 3ms/step - loss: 0.4070 - accuracy: 0.8083\n",
            "Epoch 2/2\n",
            "21367/21367 [==============================] - 64s 3ms/step - loss: 0.2104 - accuracy: 0.9161\n",
            "5342/5342 [==============================] - 2s 427us/step\n",
            "0.857918381690979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnEX1KVln3-O",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "We see that not performing lemmatization does not improve the accuracy significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io4eDIXPn7_g",
        "colab_type": "text"
      },
      "source": [
        "## **Model 4 - Including stop words**\n",
        "\n",
        "We test the effect that stop words have on the model. In general NLP models, we generally remove stop words. But our theory is that the stop words might actually have an effect in identifying the sarcasm in a sentence.\n",
        "\n",
        "We want to see if in detecting sarcasm, the **effect of stop words** plays a role in improving the efficiency of our model.\n",
        "\n",
        "*Reference : https://towardsdatascience.com/why-you-should-avoid-removing-stopwords-aa7a353d2a52*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfF8G-GfoG2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "outputId": "d338b040-49fc-422f-f978-429a9dcb6349"
      },
      "source": [
        "#@title Including stop words\n",
        "\n",
        "#Lemmatization\n",
        "lmt = WordNetLemmatizer()\n",
        "def lem_fn(input_series):\n",
        "    a  =  [lmt.lemmatize(word) for word in input_series ]\n",
        "    return(a)\n",
        "\n",
        "sarcasm_master['lem_headline'] = sarcasm_master['rem_stp_headline'].apply(lem_fn) \n",
        "\n",
        "tkn = Tokenizer(num_words=10000)\n",
        "tkn.fit_on_texts(sarcasm_master['lem_headline'])\n",
        "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['lem_headline'])\n",
        "\n",
        "total_words = len(tkn.word_index)\n",
        "\n",
        "#Add padding in front for the tokenized list\n",
        "\n",
        "#Find max length of the headline array length to add as maximum pad length\n",
        "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
        "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
        "sarcasm_master['sanslem_headline'] = X.tolist()\n",
        "\n",
        "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "include_sw_accuracy=build_model(X_train, y_train, X_test, y_test)\n",
        "print(include_sw_accuracy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 128)         3094656   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,234,561\n",
            "Trainable params: 3,234,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "21367/21367 [==============================] - 61s 3ms/step - loss: 0.4274 - accuracy: 0.8040\n",
            "Epoch 2/2\n",
            "21367/21367 [==============================] - 60s 3ms/step - loss: 0.2350 - accuracy: 0.9035\n",
            "5342/5342 [==============================] - 2s 407us/step\n",
            "0.8586671948432922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooyEtmWppW5T",
        "colab_type": "text"
      },
      "source": [
        "**Results:**\n",
        "\n",
        "We see that the accuracy hasn't increased too much from the base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHh0lMwnpak_",
        "colab_type": "text"
      },
      "source": [
        "## **Hyperparameter Tuning**\n",
        "\n",
        "We now want to focus on hyperparameter tunings. The various parameters in consideration are\n",
        "\n",
        "1. Layer activation\n",
        "2. Number of epochs\n",
        "3. Optimizer, etc.\n",
        "\n",
        "We are going to use **Grid search** for selecting the best parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stL3c30Mpnh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorization \n",
        "\n",
        "tkn = Tokenizer(num_words=10000)\n",
        "tkn.fit_on_texts(sarcasm_master['rem_stp_headline'])\n",
        "sarcasm_master['tkn_headline'] = tkn.texts_to_sequences(sarcasm_master['rem_stp_headline'])\n",
        "\n",
        "total_words = len(tkn.word_index)\n",
        "\n",
        "#Add padding in front for the tokenized list\n",
        "\n",
        "#Find max length of the headline array length to add as maximum pad length\n",
        "max_pad_length = sarcasm_master.tkn_headline.map(lambda x: len(x)).max()\n",
        "\n",
        "X = pad_sequences(sarcasm_master['tkn_headline'], maxlen= max_pad_length, padding='pre')\n",
        "sarcasm_master['final_headline'] = X.tolist()\n",
        "\n",
        "Y = sarcasm_master['is_sarcastic'].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPgx1VwapqqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(optimizer='adam', activation='relu'):\n",
        "  embed_size = 128\n",
        "  model = Sequential()\n",
        "  \n",
        "  #Embedding Layer\n",
        "  model.add(Embedding( total_words,embed_size))\n",
        "\n",
        "  #LSTM input layer\n",
        "  model.add(LSTM(embed_size, activation='relu'))\n",
        "  \n",
        "  #Intermediate layer\n",
        "  model.add(Dense(64, activation ='relu'))\n",
        "  \n",
        "  #OutputLayer\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXBRj3eSpunE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "771b054e-7566-47e3-d0fe-ee65446b7de8"
      },
      "source": [
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "model1 = KerasClassifier(build_fn=create_model, epochs=2, batch_size=16)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = dict(optimizer=['sgd', 'adam'], \n",
        "              epochs=[2],\n",
        "              batch_size=[15], \n",
        "              activation=['relu','tanh'])\n",
        "\n",
        "# Create a random search cv object and fit it to the data\n",
        "grid_search = GridSearchCV(model1, params, cv=3, scoring='accuracy')\n",
        "random_search_results = grid_search.fit(X, Y)\n",
        "# Print results\n",
        "print(random_search_results.best_score_,random_search_results.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "17806/17806 [==============================] - 103s 6ms/step - loss: 0.4491 - accuracy: 0.8023\n",
            "Epoch 2/2\n",
            "17806/17806 [==============================] - 104s 6ms/step - loss: 0.2124 - accuracy: 0.9156\n",
            "Epoch 1/2\n",
            "17806/17806 [==============================] - 101s 6ms/step - loss: 0.4365 - accuracy: 0.8027\n",
            "Epoch 2/2\n",
            "17806/17806 [==============================] - 100s 6ms/step - loss: 0.2225 - accuracy: 0.9141\n",
            "Epoch 1/2\n",
            "17806/17806 [==============================] - 103s 6ms/step - loss: 0.4203 - accuracy: 0.8115\n",
            "Epoch 2/2\n",
            "17806/17806 [==============================] - 101s 6ms/step - loss: 0.2093 - accuracy: 0.9165\n",
            "Epoch 1/2\n",
            "17806/17806 [==============================] - 100s 6ms/step - loss: 0.4058 - accuracy: 0.8076\n",
            "Epoch 2/2\n",
            "17806/17806 [==============================] - 101s 6ms/step - loss: 0.2052 - accuracy: 0.9176\n",
            "Epoch 1/2\n",
            "17806/17806 [==============================] - 98s 6ms/step - loss: 0.4086 - accuracy: 0.8116\n",
            "Epoch 2/2\n",
            "16215/17806 [==========================>...] - ETA: 8s - loss: 0.2018 - accuracy: 0.9214"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4q5QNNep2xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Epoch 5 accuracy 82.8%\n",
        "embed_size = 128\n",
        "model = Sequential()\n",
        "  \n",
        "#Embedding Layer\n",
        "model.add(Embedding( total_words,embed_size))\n",
        "\n",
        "#LSTM input layer\n",
        "model.add(LSTM(embed_size, activation='relu'))\n",
        "  \n",
        "#Intermediate layer\n",
        "model.add(Dense(64, activation ='relu'))\n",
        "  \n",
        "#OutputLayer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=5)\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHMaD3FOp3g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Epoch 10 accuracy 84.5%\n",
        "embed_size = 128\n",
        "model = Sequential()\n",
        "  \n",
        "#Embedding Layer\n",
        "model.add(Embedding( total_words,embed_size))\n",
        "\n",
        "#LSTM input layer\n",
        "model.add(LSTM(embed_size, activation='relu'))\n",
        "  \n",
        "#Intermediate layer\n",
        "model.add(Dense(64, activation ='relu'))\n",
        "  \n",
        "#OutputLayer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "model.fit(X_train,y_train,epochs=10)\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEHm6xBGp5wI",
        "colab_type": "text"
      },
      "source": [
        "**Results**\n",
        "\n",
        "From the grid search we get the following results:\n",
        "\n",
        "1. The best optimizer for our model is adam\n",
        "\n",
        "2. The best activation to use is relu\n",
        "\n",
        "We also try various epoch values : 2,5,10\n",
        "\n",
        "2 : Training accuracy- 91.9 Testing accuracy - 85.6\n",
        "\n",
        "5 : Training accuracy- 98.7 Testing accuracy - 82.8\n",
        "\n",
        "10 : Training accuracy- 99.3 Testing accuracy - 83.3\n",
        "\n",
        "We see that for epochs higher than 2, even if the training accuracy increases the testing accuracy goes down. This could be because of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "977SpPI3qHqK",
        "colab_type": "text"
      },
      "source": [
        "## **Final Model**\n",
        "\n",
        "The final model we build is a Keras model with LSTM\n",
        "\n",
        "Prepocessing : Removing stop words, punctuations, digits and converting to lower case\n",
        "\n",
        "Epochs : 2\n",
        "\n",
        "Activation : relu\n",
        "\n",
        "Output Activation : sigmoid\n",
        "\n",
        "Optimizer : adam\n",
        "\n",
        "Training accuracy : 91.9%\n",
        "\n",
        "Testing accuracy : 85.6%"
      ]
    }
  ]
}